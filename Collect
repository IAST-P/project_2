from sqlalchemy import create_engine, text
from sqlalchemy.exc import OperationalError
from sqlalchemy.exc import SQLAlchemyError
import requests
from requests.auth import HTTPBasicAuth 
import json
import numpy as np
import pandas as pd
def write_to_sql(df, table_name):
    # Create a connection string for MySQL using SQLAlchemy
    user = 'user'
    password = 'password'
    host = 'host'
    database = 'database'
    engine = create_engine(f'mysql+pymysql://{user}:{password}@{host}/{database}')
    try:
        df.to_sql(table_name, con=engine, if_exists='append', index=False)
        print(f"Data written successfully to the '{table_name}' table.")
    except SQLAlchemyError as e:
        print(f"Error occurred while writing to the database: {e}")
    finally:
        engine.dispose()
        
def fetch_data(api_url, username, password):
    try:
        response = requests.get(api_url, auth=HTTPBasicAuth(username, password))
        response.raise_for_status()  # Raise an error for bad status codes
        data = response.json()  # Assuming the response is in JSON format
        return data
    except requests.exceptions.RequestException as e:
        print(f"Error fetching data: {e}")
        return None
def add_to_dict (df, prefix, bd_table, write_fn, table_name, id_dict):
    prefix_2 = 'creatioContactId' if bd_table == '_operator' else 'creatioId'
    prefix_map = {'_operator': 'name_', '_course': 'title'}
    prefix_3 = prefix_map.get(bd_table, 'label')
    lll = id_dict[id_dict['table']==bd_table]
    existing_ids = set(lll['id'])
    if prefix == 'leadStageId':
        df[prefix] = df[prefix].fillna("others")
        t = df[~df[prefix].isin(existing_ids)][[prefix]]
        t.rename(columns={prefix: prefix_2}, inplace=True)
    else:
        df[f'{prefix}_value'] = df[f'{prefix}_value'].fillna("others")
        t = df[~df[f'{prefix}_value'].isin(existing_ids)][[f'{prefix}_displayValue', f'{prefix}_value']]
        t.rename(columns={f'{prefix}_value': prefix_2, f'{prefix}_displayValue': prefix_3}, inplace=True)
    t = t.drop_duplicates(subset=prefix_2)
    if not t.empty:
        print(f'--Add Dict from {table_name}')
        new_data = pd.DataFrame({
            'id': t[prefix_2].tolist(), 
            'table': [bd_table] * len(t)
        })
        write_to_sql(t, bd_table)
        id_dict = pd.concat([id_dict, new_data], ignore_index=True)
        print('---------------------------')
        return id_dict
    else:
        return id_dict
def preper_data(daf, primery_value=None):
    suffixes = ('primaryImageValue', 'primaryColorValue')
    daf = daf[[col for col in df.columns if not col.endswith(suffixes)]]
    df_columns = set(daf.columns)
    list_for_change = ['StartDate', 'DueDate', 'ModifiedOn', 'CreatedOn', 'WtelBridgedAt', 'WtelCreatedAt', 
                       'WtelAnsweredAt', 'WtelHangupAt', 'WtelStoredAt', 'WtelCreatedAt', 'MovedToFinalStateOn', 
                       'WtelQueueJoinedTime', 'WtelQueueBridgedAt', 'WtelQueueLivingAt', 'UsrDate']
    list_for_change = [i for i in list_for_change if i in df_columns]
    if list_for_change and len(list_for_change)>0:
        for col in list_for_change:
            daf.loc[:, col] = pd.to_datetime(daf[col], errors='coerce')
    for i in ['timestamp', 'eventDate']:
        if i in df_columns:
            daf[i] = pd.to_datetime(pd.to_numeric(daf[i], errors='coerce')) 
    list_for_change = ['type', 'timestamp', 'online', 'name', 'Status', 'Owner', 'Lead']
    list_for_change = {item: item + '_' for item in list_for_change}
    list_for_change = {key: value for key, value in list_for_change.items() if key in df_columns}
    if list_for_change and len(list_for_change)>0:
        daf = daf.rename(columns=list_for_change)  # Assign the result back to df
    if primery_value and primery_value in df_columns:
        daf = daf.dropna(subset=[primery_value])
        daf = daf.drop_duplicates(subset=primery_value)
    return daf
def data_chech (data,j):
    if j == 'events':
        return bool(data)
    else:
        return bool(data and data['status'] == 'ok')
int_columns = ['amoId', 'UsrChatMark_displayValue', 'UsrChatIdEst', 'UsrCallMark_displayValue', 
               'WtelCallCountToLine', 'WtelCallCountToClient', 'UsrAmoId', 'UsrPlan', 'UsrDealbudget', 'UsrFullcoursefee', 'UsrAmountofdiscount']
username = 'pk-api'
password = 'afdg%YHWdsg!@3rsGSgssd'
if __name__ == "__main__":

    id_dict = pd.DataFrame(columns=['table', 'id'])
    lookups_dict = ['lookups1', 'lookups2', 'lookups3', 'lookups4', 'lookups5', 'lookups6', 'lookups7']
    for i in lookups_dict:
        sufix = 'creatioContactId' if i == 'operator' else 'creatioId'
        ttt = '_'+i.replace('-', '_')
        api_url = f"https://url_for_api?type={i}&all=True"
        data = fetch_data(api_url, username, password)
        if data:
            df = pd.json_normalize(data['body'], sep='_')
            if len(df) > 0:
                df = preper_data(df, sufix)
                for i_int in int_columns:
                    if i_int in df.columns:
                        df[i_int] = pd.to_numeric(df[i_int], errors='coerce').fillna(0).astype(int)
                if i == 'operator':
                    df['online_'] = df['online_'].astype(bool)
                    df['enabled'] = df['enabled'].astype(bool)
                    df['departments'] = df['departments'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)
                    df['queues'] = df['queues'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)
                write_to_sql(df, ttt)
            new_data = pd.DataFrame({
                'id': df[sufix].tolist(), 
                'table': [ttt] * len(df)})
            id_dict = pd.concat([id_dict, new_data], ignore_index=True)    
            
    l_table = ['table1', 'table2', 'table3', 'table4', 'table5', 'table6']
    key_add_to_dict = {
        'table1' : [['Owner', '_operator'], ['UsrCourselist', '_course'], ['UsrApplicantSource', '_lead_source'], ['QualifyStatus', '_lead_stage']],
        'table2' : [['CreatedBy', '_operator']],
        'table3' : [['CreatedBy', '_operator'], ['Priority', '_activity_priority'], ['ActivityCategory', '_activity_category'],
                        ['Status', '_activity_result'], ['Owner', '_operator']],
        'table4': [['CreatedBy', '_operator']],
        'table5' : [['leadStageId', '_lead_stage']], 
        'table6' : [['UsrManager', '_operator']]
    }
    delete_columns = [
        'CreatedBy_displayValue', 'ModifiedBy_displayValue', 'Priority_displayValue', 'ActivityCategory_displayValue', 'Status_displayValue',
        'UsrCourselist_displayValue', 'UsrApplicantSource_displayValue', 'Owner_displayValue', 'QualifyStatus_displayValue', 
        'UsrChatMark_value', 'UsrChatMark', 'LeadDisqualifyReason_value', 'LeadTypeStatus_value', 'UsrPaymentmethod_value', 
        'UsrDealType_value', 'UsrRejectionReason_value', 'UsrCourseType_value', 'WtelOperator_value', 'UsrCallMark_value', 
        'WtelTransferTo_value', 'Notes', 'Type_value', 'UsrSubproject_value', 'Result_value', 'Result', 'Contact', 'ActivityCategory', 
        'WtelChats', 'CreatedBy', 'Lead_', 'UsrProject', 'UsrSubproject', 'WtelOperator', 'WtelTransferFrom', 'WtelTransferTo', 
        'UsrCallMark', 'WtelParentCDR', 'WtelContact', 'WtelNewHangupBy', 'WtelDirection', 'UsrOwnerIdEst', 'Status_', 'LeadType', 
        'UsrCourseType', 'UsrRejectionReason', 'UsrCourselist', 'UsrPaymentmethod', 'UsrApplicantSource', 'Owner_', 'UsrDealType', 'QualifiedContact',
        'UsrManager_primaryImageValue', 'UsrManager_primaryColorValue', 'UsrPrcent', 'UsrManager_displayValue']

    for j in l_table:
        i_offset = 0
        ttt = '_'+j.replace('-', '_')
        print(f'--Work with table {j}')
        while i_offset < 5000:
            print(f'---Loop number {i_offset/500+1}')
            if j == 'events':
                    api_url = f"https:///url_for_api?limit=500&offset={i_offset}"
            else:
                api_url = f"https:///url_for_api/{j}?limit=500&offset={i_offset}"
            data = fetch_data(api_url, username, password)
            if data_chech(data,j):
                if len(df) > 0:
                    df = pd.json_normalize(data['body'], sep='_') if j != 'events' else pd.json_normalize(data, sep='_')
                    if j == 'table1':
                        df['customFields'] = df['customFields'].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)
                    df = preper_data(df)
                    for i_int in int_columns:
                        if i_int in df.columns:
                            df[i_int] = pd.to_numeric(df[i_int], errors='coerce').fillna(0).astype(int)
                    for value in key_add_to_dict[j]:
                        id_dict = add_to_dict(df, value[0], value[1], write_to_sql,ttt, id_dict)
                    df = df[[col for col in df.columns if col not in delete_columns]]
                    write_to_sql(df, ttt)
                    if df.shape[0] < 500:
                        print(df.shape)
                        break                
                else:
                    print('BREAK! len df = 0')
                    break  
            else:
                print('BREAK! data is enpty or startus != ok')
                break
            i_offset += 500
